{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import pandas_profiling\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context('poster')\n",
    "from sklearn.impute import SimpleImputer\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from pandas.plotting import scatter_matrix\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from pandas.plotting import parallel_coordinates\n",
    "from pandas.plotting import lag_plot\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "## Load Relevant 2003 and 2004 LEAPS Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2003 leaps data\n",
    "child_03 = pd.read_stata('/Users/bentaylor/Documents/Data/LEAPS data/2003/public_child1.dta',\n",
    "            columns = ['childcode', 'ch1_s1q3'])\n",
    "child_roster_03 = pd.read_stata('/Users/bentaylor/Documents/Data/LEAPS data/2003/public_childroster1.dta',\n",
    "            columns = ['childcode', 'cr1_s1q5', 'cr1_s2q6'])\n",
    "hhs_household_03 = pd.read_stata('/Users/bentaylor/Documents/Data/LEAPS data/2003/public_hhsurvey1_household.dta',\n",
    "            columns = ['hhid', 'mauzaid', 'hf1_s13q1_have', 'hf1_s13q3_have', 'hm1_s11q1'])\n",
    "master_children_03 = pd.read_stata('/Users/bentaylor/Documents/Data/LEAPS data/2003/public_master_children1.dta',\n",
    "            columns = ['childcode', 'hhid', 'child_teachercode1', 'child_schoolid1',\n",
    "                      'child_english_scale1', 'child_urdu_scale1', 'child_math_scale1', 'child_female'])\n",
    "teacher_roster_03 = pd.read_stata('/Users/bentaylor/Documents/Data/LEAPS data/2003/public_teacherroster1.dta',\n",
    "            columns = ['child_teachercode1', 'tr1_s1q2', 'tr1_s1q4', 'tr1_s1q7', 'tr1_s1q8', 'tr1_s1q9',\n",
    "                       'tr1_s1q10', 'tr1_s1q11'])\n",
    "                \n",
    "# 2004 leaps data\n",
    "master_children_04 = pd.read_stata('/Users/bentaylor/Documents/Data/LEAPS data/2004/public_master_children2.dta',\n",
    "            columns = ['childcode', 'hhid', 'child_teachercode2', 'child_female','child_english_scale2', 'child_math_scale2', 'child_urdu_scale2', 'child_class2'])\n",
    "child_04 = pd.read_stata('/Users/bentaylor/Documents/Data/LEAPS data/2004/public_child2.dta',\n",
    "            columns = ['childcode', 'ch2_s1q3', 'ch2_s2q2', 'ch2_s2q3']) # ch2_s0q1_code from correlation assessment\n",
    "child_roster_04 = pd.read_stata('/Users/bentaylor/Documents/Data/LEAPS data/2004/public_childroster2.dta',\n",
    "            columns = ['childcode', 'cr2_s2q6', 'cr2_s2q7'])\n",
    "hhs_household_04 = pd.read_stata('/Users/bentaylor/Documents/Data/LEAPS data/2004/public_hhsurvey2_household.dta', convert_categoricals=False,\n",
    "            columns = ['hhid', 'h2_s0q1_code', 'h2_s13q8', 'h2_s0q4_code'])\n",
    "hhs_member_04 = pd.read_stata('/Users/bentaylor/Documents/Data/LEAPS data/2004/public_hhsurvey2_member.dta',\n",
    "            columns = ['hhid', 'h2_s4q3_type', 'h2_s4q4',\n",
    "                        'h2_s10q4_sub2', 'h2_s5q2e3'])\n",
    "hhs_school_04 = pd.read_stata('/Users/bentaylor/Documents/Data/LEAPS data/2004/public_hhsurvey2_school.dta',\n",
    "            columns = ['hhid'])\n",
    "teacher_04 = pd.read_stata('/Users/bentaylor/Documents/Data/LEAPS data/2004/public_teacher2.dta',\n",
    "            columns = ['teachercode2t','tq2_s3q1','tq2_s8q1','tq2_s8q3', 'tq2_s8q5'])\n",
    "teacher_roster_04 = pd.read_stata('/Users/bentaylor/Documents/Data/LEAPS data/2004/public_teacherroster2.dta',\n",
    "            columns = ['teachercode2tr', 'tr2_q4', 'tr2_q8', 'tr2_q7', 'tr2_q11'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make DataFrame for 2003: df2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_03 = master_children_03.rename(columns = {'child_english_scale1': 'english', 'child_urdu_scale1': \n",
    "                'urdu', 'child_math_scale1': 'math', 'child_female': 'student_sex'})\n",
    "\n",
    "merge1_03 = pd.merge(grades_03, child_roster_03,\n",
    "                on = 'childcode', how = 'left',suffixes=('left','right'))\n",
    "merge1_03 = merge1_03.rename(columns = {'childcode': 'childcode', 'cr1_s1q5': 'grade',\n",
    "                'cr1_s2q6': 'teacher_rates_child_how_good_in_studies'})\n",
    "\n",
    "merge2_03 = pd.merge(merge1_03, child_03,\n",
    "                on = 'childcode', how = 'left', suffixes = ('left','right'))\n",
    "merge2_03 = merge2_03.rename(columns = {'childcode': 'childcode',\n",
    "                'ch1_s1q3': 'child_studied_at_diff_school'})\n",
    "\n",
    "merge3_03 = pd.merge(merge2_03, teacher_roster_03,\n",
    "                on = 'child_teachercode1', how = 'left', suffixes = ('left','right'))\n",
    "merge3_03 = merge3_03.rename(columns = {'child_teachercode1': 'child_teachercode', 'tr1_s1q2': 'teacher_sex',\n",
    "                'tr1_s1q4': 'teacher_years_teaching',\n",
    "                'tr1_s1q7': 'teacher_qualifications', 'tr1_s1q8': 'teacher_training', 'tr1_s1q9': 'salary_monthly_Rs',\n",
    "                'tr1_s1q10': 'teacher_from_mauza',\n",
    "                'tr1_s1q11': 'teacher_days_absent_last_mo'})\n",
    "\n",
    "df2003 = pd.merge(merge3_03, hhs_household_03,\n",
    "                on = 'hhid', how = 'left', suffixes = ('left','right'))\n",
    "df2003 = df2003.rename(columns = {                                \n",
    "                'hhid': 'hhid', 'hf1_s13q1_have': 'print_have',\n",
    "                'hf1_s13q3_have': 'i_vis_have', # df2004.tv corresponds with this.\n",
    "                'hm1_s10q1': 'death_5_years',\n",
    "                'hm1_s11q1': 'own_agri_land_last_2_seasons'})\n",
    "\n",
    "# add grade_median and grade_mean to df2003\n",
    "df2003.insert(0, 'grade_median', df2003.iloc[:,3:6].median(numeric_only = True, axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make DataFrame for 2004: df2004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_04 = master_children_04\n",
    "grades_04 = grades_04.rename(columns = {'childcode': 'childcode', 'hhid': 'hhid',\n",
    "                'child_teachercode2': 'child_teachercode',\n",
    "                'child_female': 'student_sex', 'child_english_scale2': 'english',\n",
    "                'child_math_scale2': 'math', 'child_urdu_scale2': 'urdu', 'child_class2': 'grade'})\n",
    "\n",
    "# 04 hh_surveys\n",
    "merge1_04 = pd.merge(grades_04, hhs_household_04, on = 'hhid', how = 'left')\n",
    "\n",
    "merge2_04 = pd.merge(merge1_04, hhs_member_04, on = 'hhid', how = 'left')\n",
    "merge2_04 = merge2_04.rename(columns = {'h2_s4q3_type': 'school_type',\n",
    "                'h2_s4q4': 'studied_at_same_school_as_last_year'})\n",
    "\n",
    "merge3_04 = pd.merge(merge2_04, hhs_school_04, on='hhid', how='left')\n",
    "\n",
    "# 04 teachers\n",
    "teacher_04 = teacher_04.rename(columns = {'teachercode2t': 'teachercode','tq2_s3q1': 'teacher_sex',\n",
    "                'tq2_s8q1': 'teacher_survey_absent_emergency', 'tq2_s8q3':'teacher_survey_absent_office_work',\n",
    "                'tq2_s8q5': 'teacher_survey_absent_other_work'})\n",
    "merge3_04.insert(2, 'teachercode', teacher_04['teachercode']) # merge3_04 needs column 'teachercode' to merge on.\n",
    "merge4_04 = pd.merge(merge3_04, teacher_04,\n",
    "                on = 'teachercode', how = 'left') # this is a new kind of data, corresponding to teacher_days_absent_last_mo\n",
    "\n",
    "teacher_roster_04 = teacher_roster_04.rename(columns = {'teachercode2tr': 'teachercode',\n",
    "                'tr2_q4': 'teacher_years_teaching',\n",
    "                'tr2_q7': 'teacher_qualifications', 'tr2_q8': 'teacher_training',\n",
    "                'tr2_q11': 'teacher_from_mauza'})\n",
    "merge5_04 = pd.merge(merge4_04, teacher_roster_04, on = 'teachercode', how = 'left')\n",
    "\n",
    "# 04 students\n",
    "merge6_04 = pd.merge(merge5_04, child_04, on = 'childcode', how = 'left')\n",
    "merge6_04 = merge6_04.rename(columns = {'ch2_s1q3': 'child_studied_at_diff_school',\n",
    "                'ch2_s2q2': 'radio', 'ch2_s2q3': 'television'}) # radio and TV replace audio and vis_i of 2003\n",
    "                      \n",
    "merge7_04 = pd.merge(merge6_04, child_roster_04, on = 'childcode', how = 'left')\n",
    "df2004 = merge7_04.rename(columns = {'cr2_s2q6': 'child_days_absent_last_mo',\n",
    "                # The online data does not specify 'month', but must be monthly because the range is 0-31.\n",
    "                'cr2_s2q7': 'teacher_rates_child_how_good_in_studies', 'h2_s0q1_code': 'supervisor_code',\n",
    "                'h2_s13q8': 'hh_child_in_govt_primary_school', 'h2_s0q4_code': 'tehsil_census_code',\n",
    "                'h2_s10q4_sub2': 'child_helped', 'h2_s5q2e3': 'type_of_housework_timeslot_5'})\n",
    "\n",
    "# add grade_median and grade_mean to df2004\n",
    "df2004.insert(0, 'grade_median', df2004.iloc[:, 4:7].median(numeric_only = True, axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of and Solutions for df2003 and df2004\n",
    "### df2003 Analysis\n",
    "The English, Urdu, and Math columns have several NaNs, and the median of the three are the target variable. They must all be dropped.<br>\n",
    "Household (12,738) and teacher (~7,350) questionnaires can be left as NaN, as that's how the data gatherers intended the missing amount to look (unless I want to fill the missing events for those who filled out the questionnaires).<br><br>\n",
    "\n",
    "### df2004 Analysis\n",
    "As with df2003, The English, Urdu, and Math columns have several NaNs, and the median of the three are the target variable. They must all be dropped.<br>\n",
    "The Household (~8,100) and teacher (10,8361) questionnaires can be left as NaN, as that's how the data gatherers intended the missing amount to look (unless I want to fill the missing events for those who filled out the questionnaires).<br><br>\n",
    "\n",
    "### Solutions\n",
    "(The true target variable is the median of english, urdu, and math, and the three grades it is based on I here call the target variables in order to avoid encumbersome language.)<br>\n",
    "I will drop all the rows with NaN instances in the grade_median columns of each DataFrame because they constitute the target variable for predictive modeling.\n",
    "<br><br>\n",
    "I will fill the missing data that is less than 3% with the most common value, except for the \"sex\" column in df2004, which I will fill with the less common value \"Male\" (viz. 1).\n",
    "<br><br>\n",
    "(I have already dropped the missing data for my target variables in the grades DataFrame.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTIONS\n",
    "\n",
    "What do I do with majorly missing data? It's not a problem conceptually but is when I think of how to put it in code.<br>\n",
    "Should I convert grade to integers? (3rd or 4th grade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop all NaN values from the target variable per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2003 = df2003[df2003['grade_median'].notna()]\n",
    "df2003 = df2003[df2003['english'].notna()]\n",
    "df2003 = df2003[df2003['urdu'].notna()]\n",
    "df2003 = df2003[df2003['math'].notna()]\n",
    "\n",
    "df2004 = df2004[df2004['grade_median'].notna()]\n",
    "df2004 = df2004[df2004['english'].notna()]\n",
    "df2004 = df2004[df2004['urdu'].notna()]\n",
    "df2004 = df2004[df2004['math'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df2003: Fill in the missing values of the missing data that is less than 3%. I use sklearn.impute.SimpleImputer¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "imr = SimpleImputer(strategy='most_frequent')\n",
    "imr = imr.fit(df2003[['teacher_training']])\n",
    "df2003.teacher_training = imr.transform(df2003[['teacher_training']]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "imr = SimpleImputer(strategy='most_frequent')\n",
    "imr = imr.fit(df2003[['teacher_days_absent_last_mo']])\n",
    "df2003.teacher_days_absent_last_mo = imr.transform(df2003[['teacher_days_absent_last_mo']]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "imr = SimpleImputer(strategy='most_frequent')\n",
    "imr = imr.fit(df2003[['teacher_days_absent_last_mo']])\n",
    "df2003.teacher_days_absent_last_mo = imr.transform(df2003[['teacher_days_absent_last_mo']]).ravel()\n",
    "# I change the floats to integers because no one missed a fraction of a day in this survey,\n",
    "# indicating such was not an option for participants.\n",
    "df2003.teacher_days_absent_last_mo = df2003.teacher_days_absent_last_mo.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "imr = SimpleImputer(strategy='most_frequent')\n",
    "imr = imr.fit(df2003[['teacher_from_mauza']])\n",
    "df2003.teacher_from_mauza = imr.transform(df2003[['teacher_from_mauza']]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "imr = SimpleImputer(strategy='most_frequent')\n",
    "imr = imr.fit(df2003[['teacher_years_teaching']])\n",
    "df2003.teacher_years_teaching = imr.transform(df2003[['teacher_years_teaching']]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "imr = SimpleImputer(strategy='most_frequent')\n",
    "imr = imr.fit(df2003[['salary_monthly_Rs']])\n",
    "df2003.salary_monthly_Rs = imr.transform(df2003[['salary_monthly_Rs']]).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df2004: Fill in the missing values of the missing data that is less than 3%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "imr = SimpleImputer(strategy='most_frequent')\n",
    "imr = imr.fit(df2004[['child_teachercode']])\n",
    "df2004.child_teachercode = imr.transform(df2004[['child_teachercode']]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "imr = SimpleImputer(strategy='most_frequent')\n",
    "imr = imr.fit(df2004[['grade']])\n",
    "df2004.grade = imr.transform(df2004[['grade']]).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If I had more computing power, I would fill the missing ~3% of data using MICE (see code below) instead of the average in each category.<br>\n",
    "cf. https://towardsdatascience.com/stop-using-mean-to-fill-missing-data-678c0d396e22\n",
    "<br><br>\n",
    "\n",
    "from impyute.imputation.cs import mice <br>\n",
    "\n",
    "X = grades.drop('childcode', axis=1).values <br>\n",
    "\n",
    "imputed = mice(X) <br>\n",
    "mice_ages = imputed[:, 2]\n",
    "\n",
    "grades.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back to Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert strings to integers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I performed this after the Cleaning Data section to make more intuitive graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Dictionaries\n",
    "# 5 is the number for NaNs\n",
    "sex_int = {'Female': 0, 'Male': 1, np.nan: 5}\n",
    "yes_no_int = {'No': 0, 'no': 0, 'Yes': 1, 'yes': 1, np.nan: 5}\n",
    "school_type_int = {'Public': 0, 'Private': 1, 'Madrassa': 2, np.nan: 5}\n",
    "\n",
    "# df2003\n",
    "df2003.student_sex = [sex_int[item] for item in df2003.student_sex] \n",
    "df2003.teacher_sex = [sex_int[item] for item in df2003.teacher_sex]\n",
    "df2003.child_studied_at_diff_school = [yes_no_int[item] for item in df2003.child_studied_at_diff_school]\n",
    "df2003.own_agri_land_last_2_seasons = [yes_no_int[item] for item in df2003.own_agri_land_last_2_seasons]\n",
    "df2003.i_vis_have = [yes_no_int[item] for item in df2003.i_vis_have]\n",
    "df2003.print_have = [yes_no_int[item] for item in df2003.print_have]\n",
    "df2003.teacher_from_mauza = [yes_no_int[item] for item in df2003.teacher_from_mauza]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2004.student_sex = [sex_int[item] for item in df2004.student_sex]\n",
    "df2004.teacher_sex = [sex_int[item] for item in df2004.teacher_sex]\n",
    "df2004.school_type = [school_type_int[item] for item in df2004.school_type]\n",
    "df2004.studied_at_same_school_as_last_year = [yes_no_int[item] for item in df2004.studied_at_same_school_as_last_year]\n",
    "df2004.teacher_survey_absent_emergency = [yes_no_int[item] for item in df2004.teacher_survey_absent_emergency]\n",
    "df2004.teacher_survey_absent_office_work = [yes_no_int[item] for item in df2004.teacher_survey_absent_office_work]\n",
    "df2004.teacher_survey_absent_other_work = [yes_no_int[item] for item in df2004.teacher_survey_absent_other_work]\n",
    "df2004.teacher_from_mauza = [yes_no_int[item] for item in df2004.teacher_from_mauza]\n",
    "df2004.child_studied_at_diff_school = [yes_no_int[item] for item in df2004.child_studied_at_diff_school]\n",
    "df2004.radio = [yes_no_int[item] for item in df2004.radio]\n",
    "df2004.television = [yes_no_int[item] for item in df2004.television]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, I fill NaN values with the lesser observed sex: males.\n",
    "imr = SimpleImputer(strategy='constant', fill_value=1)\n",
    "imr = imr.fit(df2004[['student_sex']])\n",
    "df2004.student_sex = imr.transform(df2004[['student_sex']]).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Numeric-Only DataFrames for Predictive Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric-Only DataFrame for 2003:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12110 entries, 0 to 13734\n",
      "Data columns (total 14 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   grade_median                  12110 non-null  float64\n",
      " 1   childcode                     12110 non-null  object \n",
      " 2   child_teachercode             12110 non-null  int32  \n",
      " 3   child_schoolid1               12110 non-null  int8   \n",
      " 4   english                       12110 non-null  float64\n",
      " 5   urdu                          12110 non-null  float64\n",
      " 6   math                          12110 non-null  float64\n",
      " 7   student_sex                   12110 non-null  int64  \n",
      " 8   grade                         12110 non-null  int8   \n",
      " 9   teacher_sex                   12110 non-null  int64  \n",
      " 10  salary_monthly_Rs             12110 non-null  float64\n",
      " 11  teacher_from_mauza            12110 non-null  int64  \n",
      " 12  teacher_days_absent_last_mo   12110 non-null  int64  \n",
      " 13  own_agri_land_last_2_seasons  12110 non-null  int64  \n",
      "dtypes: float64(5), int32(1), int64(5), int8(2), object(1)\n",
      "memory usage: 1.2+ MB\n",
      "\n",
      "\n",
      "No NaNs or \"None\" objects:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "grade_median                    0\n",
       "childcode                       0\n",
       "child_teachercode               0\n",
       "child_schoolid1                 0\n",
       "english                         0\n",
       "urdu                            0\n",
       "math                            0\n",
       "student_sex                     0\n",
       "grade                           0\n",
       "teacher_sex                     0\n",
       "salary_monthly_Rs               0\n",
       "teacher_from_mauza              0\n",
       "teacher_days_absent_last_mo     0\n",
       "own_agri_land_last_2_seasons    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2003_num = df2003.copy()\n",
    "df2003_num = df2003_num.drop(columns = ['hhid',\n",
    "                    'mauzaid', 'teacher_rates_child_how_good_in_studies',\n",
    "                    'teacher_years_teaching', 'teacher_qualifications', 'teacher_training',\n",
    "                    'child_studied_at_diff_school', 'print_have', 'i_vis_have'])\n",
    "print('Numeric-Only DataFrame for 2003:\\n')\n",
    "df2003_num.info()\n",
    "print('\\n\\nNo NaNs or \"None\" objects:\\n')\n",
    "df2003_num.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric-Only DataFrame for 2004:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 64218 entries, 0 to 109147\n",
      "Data columns (total 18 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   grade_median                         64218 non-null  float64\n",
      " 1   childcode                            64218 non-null  int32  \n",
      " 2   child_teachercode                    64218 non-null  float64\n",
      " 3   student_sex                          64218 non-null  float64\n",
      " 4   english                              64218 non-null  float64\n",
      " 5   math                                 64218 non-null  float64\n",
      " 6   urdu                                 64218 non-null  float64\n",
      " 7   grade                                64218 non-null  float64\n",
      " 8   school_type                          64218 non-null  int64  \n",
      " 9   studied_at_same_school_as_last_year  64218 non-null  int64  \n",
      " 10  teacher_sex                          64218 non-null  int64  \n",
      " 11  teacher_survey_absent_emergency      64218 non-null  int64  \n",
      " 12  teacher_survey_absent_office_work    64218 non-null  int64  \n",
      " 13  teacher_survey_absent_other_work     64218 non-null  int64  \n",
      " 14  teacher_from_mauza                   64218 non-null  int64  \n",
      " 15  child_studied_at_diff_school         64218 non-null  int64  \n",
      " 16  radio                                64218 non-null  int64  \n",
      " 17  television                           64218 non-null  int64  \n",
      "dtypes: float64(7), int32(1), int64(10)\n",
      "memory usage: 9.1 MB\n",
      "\n",
      "\n",
      "No NaNs or \"None\" objects:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "grade_median                           0\n",
       "childcode                              0\n",
       "child_teachercode                      0\n",
       "student_sex                            0\n",
       "english                                0\n",
       "math                                   0\n",
       "urdu                                   0\n",
       "grade                                  0\n",
       "school_type                            0\n",
       "studied_at_same_school_as_last_year    0\n",
       "teacher_sex                            0\n",
       "teacher_survey_absent_emergency        0\n",
       "teacher_survey_absent_office_work      0\n",
       "teacher_survey_absent_other_work       0\n",
       "teacher_from_mauza                     0\n",
       "child_studied_at_diff_school           0\n",
       "radio                                  0\n",
       "television                             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2004_num = df2004.copy()\n",
    "df2004_num = df2004_num.drop(columns = ['teacher_years_teaching', 'teachercode', 'teacher_qualifications',\n",
    "                    'teacher_training', 'type_of_housework_timeslot_5', 'child_helped',\n",
    "                    'teacher_rates_child_how_good_in_studies',\n",
    "                    'child_days_absent_last_mo', 'hh_child_in_govt_primary_school',\n",
    "                    'supervisor_code', 'tehsil_census_code',\n",
    "                    'hhid'])\n",
    "print('Numeric-Only DataFrame for 2004:\\n')\n",
    "df2004_num.info()\n",
    "print('\\n\\nNo NaNs or \"None\" objects:\\n')\n",
    "df2004_num.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I cram the data into a normal bell curve using boxcox and then add the fitted data into the grades DataFrame. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxcox and df2003.grade_median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boxcox will not compute numbers less than or equal to 0, so I replace 0s with the next closest number: 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2004.grade_median.replace(to_replace=0, value=1, inplace=True)\n",
    "df2004.grade_median.where(df2004.grade_median < 0.001).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_data_03, fitted_lambda_03 = stats.boxcox(df2003.grade_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxcox and df2004.grade_median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boxcox will not compute numbers less than or equal to 0, so I replace 0s with the next closest number: 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2004.grade_median.replace(to_replace=0, value=1, inplace=True)\n",
    "df2004.grade_median.where(df2004.grade_median < 0.001).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_data_04, fitted_lambda_04 = stats.boxcox(df2004.grade_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the fitted data in the DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add two columns of the fitted data from boxcox\n",
    "df2003.insert(1, 'grade_median_fitted', fitted_data_03)\n",
    "df2003_num.insert(1, 'grade_median_fitted', fitted_data_03)\n",
    "df2004.insert(1, 'grade_median_fitted', fitted_data_04)\n",
    "df2004_num.insert(1, 'grade_median_fitted', fitted_data_04)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare and Contrast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare for Predictive Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Reshape Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create arrays for features and target variable\n",
    "y2003 = df2003_num['grade_median_fitted'].copy().values\n",
    "X2003 = df2003_num.copy().drop(['grade_median', 'grade_median_fitted'], axis=1)\n",
    "X2003_no_derivatives = df2003_num.copy().drop(['grade_median', 'grade_median_fitted',\n",
    "                                'math', 'english', 'urdu'], axis=1)\n",
    "X2003_columns = X2003.copy().columns\n",
    "\n",
    "y2004 = df2004_num['grade_median_fitted'].copy().values\n",
    "X2004 = df2004_num.copy().drop('grade_median_fitted', axis=1)\n",
    "X2004_no_derivatives = df2004_num.copy().drop(['grade_median', 'grade_median_fitted',\n",
    "                                'math', 'english', 'urdu'], axis=1)\n",
    "X2004_columns = X2004.copy().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.indexes.base.Index'>\n"
     ]
    }
   ],
   "source": [
    "print(type(y2003))\n",
    "print(type(X2003))\n",
    "print(type(X2003_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Feature Scaling: Five Scalers and Three Models\n",
    "### https://towardsdatascience.com/feature-scaling-effect-of-different-scikit-learn-scalers-deep-dive-8dec775d4946"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from  sklearn.preprocessing import *\n",
    "from sklearn.linear_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressors=[StandardScaler(),MinMaxScaler(),\n",
    "PowerTransformer(method='yeo-johnson'),\n",
    "RobustScaler(quantile_range=(25,75)),MaxAbsScaler()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[Ridge(alpha=1.0), HuberRegressor(), LinearRegression()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51374, 18)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2004_math = df2004_num['math'].copy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X2004, y2004, test_size=.2, random_state=42)\n",
    "'''X_train = np.asarray(X_train)\n",
    "X_train = X_train.reshape(1, -1)\n",
    "X_test = np.asarray(X_test)\n",
    "X_test = X_test.reshape(1, -1)'''\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51374,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must be the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-ffd84be04785>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mX_train_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mX_test_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mScaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'^'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mOriginal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mScaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOriginal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Scaled'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Original'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'best'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[1;32m   2846\u001b[0m         \u001b[0mverts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medgecolors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medgecolors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2847\u001b[0m         plotnonfinite=plotnonfinite, **({\"data\": data} if data is not\n\u001b[0;32m-> 2848\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2849\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2850\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1597\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[1;32m   4441\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4442\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4443\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x and y must be the same size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4445\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must be the same size"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for regressor in regressors:\n",
    "    X_train_scaled = regressor.fit_transform(X_train)\n",
    "    X_test_scaled = regressor.transform(X_test)\n",
    "    Scaled = plt.scatter(X_train_scaled,y_train, marker='^', alpha=0.8, s=6)\n",
    "    Original = plt.scatter(X_train,y_train, s=6)\n",
    "    plt.legend((Scaled, Original),('Scaled', 'Original'),loc='best',fontsize=13)\n",
    "    plt.xlabel(\"Feature 1\")\n",
    "    plt.ylabel(\"Train Target\")         \n",
    "    plt.show()\n",
    "    X_train_scaled = X_train_scaled.reshape(-1, 1)\n",
    "    X_test_scaled = X_test_scaled.reshape(-1, 1)\n",
    "    for model in models:\n",
    "        reg_lin = model.fit(X_train_scaled, y_train)\n",
    "        y_pred = reg_lin.predict(X_test_scaled)   \n",
    "        print(\"The calculated coefficients with \", model , \"\\nand\", regressor, reg_lin.coef_,'\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
