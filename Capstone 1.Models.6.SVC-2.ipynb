{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import pandas_profiling\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context('poster')\n",
    "from sklearn.impute import SimpleImputer\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from pandas.plotting import scatter_matrix\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from pandas.plotting import parallel_coordinates\n",
    "from pandas.plotting import lag_plot\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "## Load Relevant 2003 and 2004 LEAPS Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2003 leaps data\n",
    "child_03 = pd.read_stata('/Users/bentaylor/Documents/Data/LEAPS data/2003/public_child1.dta',\n",
    "            columns = ['childcode', 'ch1_s1q3'])\n",
    "child_roster_03 = pd.read_stata('/Users/bentaylor/Documents/Data/LEAPS data/2003/public_childroster1.dta',\n",
    "            columns = ['childcode', 'cr1_s1q5', 'cr1_s2q6'])\n",
    "hhs_household_03 = pd.read_stata('/Users/bentaylor/Documents/Data/LEAPS data/2003/public_hhsurvey1_household.dta',\n",
    "            columns = ['hhid', 'mauzaid', 'hf1_s13q1_have', 'hf1_s13q3_have', 'hm1_s11q1'])\n",
    "master_children_03 = pd.read_stata('/Users/bentaylor/Documents/Data/LEAPS data/2003/public_master_children1.dta',\n",
    "            columns = ['childcode', 'hhid', 'child_teachercode1', 'child_schoolid1',\n",
    "                      'child_english_scale1', 'child_urdu_scale1', 'child_math_scale1', 'child_female'])\n",
    "teacher_roster_03 = pd.read_stata('/Users/bentaylor/Documents/Data/LEAPS data/2003/public_teacherroster1.dta',\n",
    "            columns = ['child_teachercode1', 'tr1_s1q2', 'tr1_s1q4', 'tr1_s1q7', 'tr1_s1q8', 'tr1_s1q9',\n",
    "                       'tr1_s1q10', 'tr1_s1q11'])\n",
    "                \n",
    "# 2004 leaps data\n",
    "master_children_04 = pd.read_stata('/Users/bentaylor/Documents/Data/LEAPS data/2004/public_master_children2.dta',\n",
    "            columns = ['childcode', 'hhid', 'child_teachercode2', 'child_female','child_english_scale2', 'child_math_scale2', 'child_urdu_scale2', 'child_class2'])\n",
    "child_04 = pd.read_stata('/Users/bentaylor/Documents/Data/LEAPS data/2004/public_child2.dta',\n",
    "            columns = ['childcode', 'ch2_s1q3', 'ch2_s2q2', 'ch2_s2q3']) # ch2_s0q1_code from correlation assessment\n",
    "child_roster_04 = pd.read_stata('/Users/bentaylor/Documents/Data/LEAPS data/2004/public_childroster2.dta',\n",
    "            columns = ['childcode', 'cr2_s2q6', 'cr2_s2q7'])\n",
    "hhs_household_04 = pd.read_stata('/Users/bentaylor/Documents/Data/LEAPS data/2004/public_hhsurvey2_household.dta', convert_categoricals=False,\n",
    "            columns = ['hhid', 'h2_s0q1_code', 'h2_s13q8', 'h2_s0q4_code'])\n",
    "hhs_member_04 = pd.read_stata('/Users/bentaylor/Documents/Data/LEAPS data/2004/public_hhsurvey2_member.dta',\n",
    "            columns = ['hhid', 'h2_s4q3_type', 'h2_s4q4',\n",
    "                        'h2_s10q4_sub2', 'h2_s5q2e3'])\n",
    "hhs_school_04 = pd.read_stata('/Users/bentaylor/Documents/Data/LEAPS data/2004/public_hhsurvey2_school.dta',\n",
    "            columns = ['hhid'])\n",
    "teacher_04 = pd.read_stata('/Users/bentaylor/Documents/Data/LEAPS data/2004/public_teacher2.dta',\n",
    "            columns = ['teachercode2t','tq2_s3q1','tq2_s8q1','tq2_s8q3', 'tq2_s8q5'])\n",
    "teacher_roster_04 = pd.read_stata('/Users/bentaylor/Documents/Data/LEAPS data/2004/public_teacherroster2.dta',\n",
    "            columns = ['teachercode2tr', 'tr2_q4', 'tr2_q8', 'tr2_q7', 'tr2_q11'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make DataFrame for 2003: df2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_03 = master_children_03.rename(columns = {'child_english_scale1': 'english', 'child_urdu_scale1': \n",
    "                'urdu', 'child_math_scale1': 'math', 'child_female': 'student_sex'})\n",
    "\n",
    "merge1_03 = pd.merge(grades_03, child_roster_03,\n",
    "                on = 'childcode', how = 'left',suffixes=('left','right'))\n",
    "merge1_03 = merge1_03.rename(columns = {'childcode': 'childcode', 'cr1_s1q5': 'grade',\n",
    "                'cr1_s2q6': 'teacher_rates_child_how_good_in_studies'})\n",
    "\n",
    "merge2_03 = pd.merge(merge1_03, child_03,\n",
    "                on = 'childcode', how = 'left', suffixes = ('left','right'))\n",
    "merge2_03 = merge2_03.rename(columns = {'childcode': 'childcode',\n",
    "                'ch1_s1q3': 'child_studied_at_diff_school'})\n",
    "\n",
    "merge3_03 = pd.merge(merge2_03, teacher_roster_03,\n",
    "                on = 'child_teachercode1', how = 'left', suffixes = ('left','right'))\n",
    "merge3_03 = merge3_03.rename(columns = {'child_teachercode1': 'child_teachercode', 'tr1_s1q2': 'teacher_sex',\n",
    "                'tr1_s1q4': 'teacher_years_teaching',\n",
    "                'tr1_s1q7': 'teacher_qualifications', 'tr1_s1q8': 'teacher_training', 'tr1_s1q9': 'salary_monthly_Rs',\n",
    "                'tr1_s1q10': 'teacher_from_mauza',\n",
    "                'tr1_s1q11': 'teacher_days_absent_last_mo'})\n",
    "\n",
    "df2003 = pd.merge(merge3_03, hhs_household_03,\n",
    "                on = 'hhid', how = 'left', suffixes = ('left','right'))\n",
    "df2003 = df2003.rename(columns = {                                \n",
    "                'hhid': 'hhid', 'hf1_s13q1_have': 'print_have',\n",
    "                'hf1_s13q3_have': 'i_vis_have', # df2004.tv corresponds with this.\n",
    "                'hm1_s10q1': 'death_5_years',\n",
    "                'hm1_s11q1': 'own_agri_land_last_2_seasons'})\n",
    "\n",
    "# add grade_median and grade_mean to df2003\n",
    "df2003.insert(0, 'grade_median', df2003.iloc[:,3:6].median(numeric_only = True, axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make DataFrame for 2004: df2004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_04 = master_children_04\n",
    "grades_04 = grades_04.rename(columns = {'childcode': 'childcode', 'hhid': 'hhid',\n",
    "                'child_teachercode2': 'child_teachercode',\n",
    "                'child_female': 'student_sex', 'child_english_scale2': 'english',\n",
    "                'child_math_scale2': 'math', 'child_urdu_scale2': 'urdu', 'child_class2': 'grade'})\n",
    "\n",
    "# 04 hh_surveys\n",
    "merge1_04 = pd.merge(grades_04, hhs_household_04, on = 'hhid', how = 'left')\n",
    "\n",
    "merge2_04 = pd.merge(merge1_04, hhs_member_04, on = 'hhid', how = 'left')\n",
    "merge2_04 = merge2_04.rename(columns = {'h2_s4q3_type': 'school_type',\n",
    "                'h2_s4q4': 'studied_at_same_school_as_last_year'})\n",
    "\n",
    "merge3_04 = pd.merge(merge2_04, hhs_school_04, on='hhid', how='left')\n",
    "\n",
    "# 04 teachers\n",
    "teacher_04 = teacher_04.rename(columns = {'teachercode2t': 'teachercode','tq2_s3q1': 'teacher_sex',\n",
    "                'tq2_s8q1': 'teacher_survey_absent_emergency', 'tq2_s8q3':'teacher_survey_absent_office_work',\n",
    "                'tq2_s8q5': 'teacher_survey_absent_other_work'})\n",
    "merge3_04.insert(2, 'teachercode', teacher_04['teachercode']) # merge3_04 needs column 'teachercode' to merge on.\n",
    "merge4_04 = pd.merge(merge3_04, teacher_04,\n",
    "                on = 'teachercode', how = 'left') # this is a new kind of data, corresponding to teacher_days_absent_last_mo\n",
    "\n",
    "teacher_roster_04 = teacher_roster_04.rename(columns = {'teachercode2tr': 'teachercode',\n",
    "                'tr2_q4': 'teacher_years_teaching',\n",
    "                'tr2_q7': 'teacher_qualifications', 'tr2_q8': 'teacher_training',\n",
    "                'tr2_q11': 'teacher_from_mauza'})\n",
    "merge5_04 = pd.merge(merge4_04, teacher_roster_04, on = 'teachercode', how = 'left')\n",
    "\n",
    "# 04 students\n",
    "merge6_04 = pd.merge(merge5_04, child_04, on = 'childcode', how = 'left')\n",
    "merge6_04 = merge6_04.rename(columns = {'ch2_s1q3': 'child_studied_at_diff_school',\n",
    "                'ch2_s2q2': 'radio', 'ch2_s2q3': 'television'}) # radio and TV replace audio and vis_i of 2003\n",
    "                      \n",
    "merge7_04 = pd.merge(merge6_04, child_roster_04, on = 'childcode', how = 'left')\n",
    "df2004 = merge7_04.rename(columns = {'cr2_s2q6': 'child_days_absent_last_mo',\n",
    "                # The online data does not specify 'month', but must be monthly because the range is 0-31.\n",
    "                'cr2_s2q7': 'teacher_rates_child_how_good_in_studies', 'h2_s0q1_code': 'supervisor_code',\n",
    "                'h2_s13q8': 'hh_child_in_govt_primary_school', 'h2_s0q4_code': 'tehsil_census_code',\n",
    "                'h2_s10q4_sub2': 'child_helped', 'h2_s5q2e3': 'type_of_housework_timeslot_5'})\n",
    "\n",
    "# add grade_median and grade_mean to df2004\n",
    "df2004.insert(0, 'grade_median', df2004.iloc[:, 4:7].median(numeric_only = True, axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of and Solutions for df2003 and df2004\n",
    "### df2003 Analysis\n",
    "The English, Urdu, and Math columns have several NaNs, and the median of the three are the target variable. They must all be dropped.<br>\n",
    "Household (12,738) and teacher (~7,350) questionnaires can be left as NaN, as that's how the data gatherers intended the missing amount to look (unless I want to fill the missing events for those who filled out the questionnaires).<br><br>\n",
    "\n",
    "### df2004 Analysis\n",
    "As with df2003, The English, Urdu, and Math columns have several NaNs, and the median of the three are the target variable. They must all be dropped.<br>\n",
    "The Household (~8,100) and teacher (10,8361) questionnaires can be left as NaN, as that's how the data gatherers intended the missing amount to look (unless I want to fill the missing events for those who filled out the questionnaires).<br><br>\n",
    "\n",
    "### Solutions\n",
    "(The true target variable is the median of english, urdu, and math, and the three grades it is based on I here call the target variables in order to avoid encumbersome language.)<br>\n",
    "I will drop all the rows with NaN instances in the grade_median columns of each DataFrame because they constitute the target variable for predictive modeling.\n",
    "<br><br>\n",
    "I will fill the missing data that is less than 3% with the most common value, except for the \"sex\" column in df2004, which I will fill with the less common value \"Male\" (viz. 1).\n",
    "<br><br>\n",
    "(I have already dropped the missing data for my target variables in the grades DataFrame.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTIONS\n",
    "\n",
    "What do I do with majorly missing data? It's not a problem conceptually but is when I think of how to put it in code.<br>\n",
    "Should I convert grade to integers? (3rd or 4th grade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop all NaN values from the target variable per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2003 = df2003[df2003['grade_median'].notna()]\n",
    "df2003 = df2003[df2003['english'].notna()]\n",
    "df2003 = df2003[df2003['urdu'].notna()]\n",
    "df2003 = df2003[df2003['math'].notna()]\n",
    "\n",
    "df2004 = df2004[df2004['grade_median'].notna()]\n",
    "df2004 = df2004[df2004['english'].notna()]\n",
    "df2004 = df2004[df2004['urdu'].notna()]\n",
    "df2004 = df2004[df2004['math'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df2003: Fill in the missing values of the missing data that is less than 3%. I use sklearn.impute.SimpleImputer¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imr = SimpleImputer(strategy='most_frequent')\n",
    "imr = imr.fit(df2003[['teacher_training']])\n",
    "df2003.teacher_training = imr.transform(df2003[['teacher_training']]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "imr = SimpleImputer(strategy='most_frequent')\n",
    "imr = imr.fit(df2003[['teacher_days_absent_last_mo']])\n",
    "df2003.teacher_days_absent_last_mo = imr.transform(df2003[['teacher_days_absent_last_mo']]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "imr = SimpleImputer(strategy='most_frequent')\n",
    "imr = imr.fit(df2003[['teacher_days_absent_last_mo']])\n",
    "df2003.teacher_days_absent_last_mo = imr.transform(df2003[['teacher_days_absent_last_mo']]).ravel()\n",
    "# I change the floats to integers because no one missed a fraction of a day in this survey,\n",
    "# indicating such was not an option for participants.\n",
    "df2003.teacher_days_absent_last_mo = df2003.teacher_days_absent_last_mo.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "imr = SimpleImputer(strategy='most_frequent')\n",
    "imr = imr.fit(df2003[['teacher_from_mauza']])\n",
    "df2003.teacher_from_mauza = imr.transform(df2003[['teacher_from_mauza']]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "imr = SimpleImputer(strategy='most_frequent')\n",
    "imr = imr.fit(df2003[['teacher_years_teaching']])\n",
    "df2003.teacher_years_teaching = imr.transform(df2003[['teacher_years_teaching']]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "imr = SimpleImputer(strategy='most_frequent')\n",
    "imr = imr.fit(df2003[['salary_monthly_Rs']])\n",
    "df2003.salary_monthly_Rs = imr.transform(df2003[['salary_monthly_Rs']]).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df2004: Fill in the missing values of the missing data that is less than 3%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "imr = SimpleImputer(strategy='most_frequent')\n",
    "imr = imr.fit(df2004[['child_teachercode']])\n",
    "df2004.child_teachercode = imr.transform(df2004[['child_teachercode']]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "imr = SimpleImputer(strategy='most_frequent')\n",
    "imr = imr.fit(df2004[['grade']])\n",
    "df2004.grade = imr.transform(df2004[['grade']]).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If I had more computing power, I would fill the missing ~3% of data using MICE (see code below) instead of the average in each category.<br>\n",
    "cf. https://towardsdatascience.com/stop-using-mean-to-fill-missing-data-678c0d396e22\n",
    "<br><br>\n",
    "\n",
    "from impyute.imputation.cs import mice <br>\n",
    "\n",
    "X = grades.drop('childcode', axis=1).values <br>\n",
    "\n",
    "imputed = mice(X) <br>\n",
    "mice_ages = imputed[:, 2]\n",
    "\n",
    "grades.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back to Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert strings to integers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I performed this after the Cleaning Data section to make more intuitive graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Dictionaries\n",
    "# 5 is the number for NaNs\n",
    "sex_int = {'Female': 0, 'Male': 1, np.nan: 5}\n",
    "yes_no_int = {'No': 0, 'no': 0, 'Yes': 1, 'yes': 1, np.nan: 5}\n",
    "school_type_int = {'Public': 0, 'Private': 1, 'Madrassa': 2, np.nan: 5}\n",
    "\n",
    "# df2003\n",
    "df2003.student_sex = [sex_int[item] for item in df2003.student_sex] \n",
    "df2003.teacher_sex = [sex_int[item] for item in df2003.teacher_sex]\n",
    "df2003.child_studied_at_diff_school = [yes_no_int[item] for item in df2003.child_studied_at_diff_school]\n",
    "df2003.own_agri_land_last_2_seasons = [yes_no_int[item] for item in df2003.own_agri_land_last_2_seasons]\n",
    "df2003.i_vis_have = [yes_no_int[item] for item in df2003.i_vis_have]\n",
    "df2003.print_have = [yes_no_int[item] for item in df2003.print_have]\n",
    "df2003.teacher_from_mauza = [yes_no_int[item] for item in df2003.teacher_from_mauza]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2004.student_sex = [sex_int[item] for item in df2004.student_sex]\n",
    "df2004.teacher_sex = [sex_int[item] for item in df2004.teacher_sex]\n",
    "df2004.school_type = [school_type_int[item] for item in df2004.school_type]\n",
    "df2004.studied_at_same_school_as_last_year = [yes_no_int[item] for item in df2004.studied_at_same_school_as_last_year]\n",
    "df2004.teacher_survey_absent_emergency = [yes_no_int[item] for item in df2004.teacher_survey_absent_emergency]\n",
    "df2004.teacher_survey_absent_office_work = [yes_no_int[item] for item in df2004.teacher_survey_absent_office_work]\n",
    "df2004.teacher_survey_absent_other_work = [yes_no_int[item] for item in df2004.teacher_survey_absent_other_work]\n",
    "df2004.teacher_from_mauza = [yes_no_int[item] for item in df2004.teacher_from_mauza]\n",
    "df2004.child_studied_at_diff_school = [yes_no_int[item] for item in df2004.child_studied_at_diff_school]\n",
    "df2004.radio = [yes_no_int[item] for item in df2004.radio]\n",
    "df2004.television = [yes_no_int[item] for item in df2004.television]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, I fill NaN values with the lesser observed sex: males.\n",
    "imr = SimpleImputer(strategy='constant', fill_value=1)\n",
    "imr = imr.fit(df2004[['student_sex']])\n",
    "df2004.student_sex = imr.transform(df2004[['student_sex']]).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Numeric-Only DataFrames for Predictive Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric-Only DataFrame for 2003:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12110 entries, 0 to 13734\n",
      "Data columns (total 14 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   grade_median                  12110 non-null  float64\n",
      " 1   childcode                     12110 non-null  object \n",
      " 2   child_teachercode             12110 non-null  int32  \n",
      " 3   child_schoolid1               12110 non-null  int8   \n",
      " 4   english                       12110 non-null  float64\n",
      " 5   urdu                          12110 non-null  float64\n",
      " 6   math                          12110 non-null  float64\n",
      " 7   student_sex                   12110 non-null  int64  \n",
      " 8   grade                         12110 non-null  int8   \n",
      " 9   teacher_sex                   12110 non-null  int64  \n",
      " 10  salary_monthly_Rs             12110 non-null  float64\n",
      " 11  teacher_from_mauza            12110 non-null  int64  \n",
      " 12  teacher_days_absent_last_mo   12110 non-null  int64  \n",
      " 13  own_agri_land_last_2_seasons  12110 non-null  int64  \n",
      "dtypes: float64(5), int32(1), int64(5), int8(2), object(1)\n",
      "memory usage: 1.2+ MB\n",
      "\n",
      "\n",
      "No NaNs or \"None\" objects:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "grade_median                    0\n",
       "childcode                       0\n",
       "child_teachercode               0\n",
       "child_schoolid1                 0\n",
       "english                         0\n",
       "urdu                            0\n",
       "math                            0\n",
       "student_sex                     0\n",
       "grade                           0\n",
       "teacher_sex                     0\n",
       "salary_monthly_Rs               0\n",
       "teacher_from_mauza              0\n",
       "teacher_days_absent_last_mo     0\n",
       "own_agri_land_last_2_seasons    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2003_num = df2003.copy()\n",
    "df2003_num = df2003_num.drop(columns = ['hhid',\n",
    "                    'mauzaid', 'teacher_rates_child_how_good_in_studies',\n",
    "                    'teacher_years_teaching', 'teacher_qualifications', 'teacher_training',\n",
    "                    'child_studied_at_diff_school', 'print_have', 'i_vis_have'])\n",
    "print('Numeric-Only DataFrame for 2003:\\n')\n",
    "df2003_num.info()\n",
    "print('\\n\\nNo NaNs or \"None\" objects:\\n')\n",
    "df2003_num.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric-Only DataFrame for 2004:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 64218 entries, 0 to 109147\n",
      "Data columns (total 18 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   grade_median                         64218 non-null  float64\n",
      " 1   childcode                            64218 non-null  int32  \n",
      " 2   child_teachercode                    64218 non-null  float64\n",
      " 3   student_sex                          64218 non-null  float64\n",
      " 4   english                              64218 non-null  float64\n",
      " 5   math                                 64218 non-null  float64\n",
      " 6   urdu                                 64218 non-null  float64\n",
      " 7   grade                                64218 non-null  float64\n",
      " 8   school_type                          64218 non-null  int64  \n",
      " 9   studied_at_same_school_as_last_year  64218 non-null  int64  \n",
      " 10  teacher_sex                          64218 non-null  int64  \n",
      " 11  teacher_survey_absent_emergency      64218 non-null  int64  \n",
      " 12  teacher_survey_absent_office_work    64218 non-null  int64  \n",
      " 13  teacher_survey_absent_other_work     64218 non-null  int64  \n",
      " 14  teacher_from_mauza                   64218 non-null  int64  \n",
      " 15  child_studied_at_diff_school         64218 non-null  int64  \n",
      " 16  radio                                64218 non-null  int64  \n",
      " 17  television                           64218 non-null  int64  \n",
      "dtypes: float64(7), int32(1), int64(10)\n",
      "memory usage: 9.1 MB\n",
      "\n",
      "\n",
      "No NaNs or \"None\" objects:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "grade_median                           0\n",
       "childcode                              0\n",
       "child_teachercode                      0\n",
       "student_sex                            0\n",
       "english                                0\n",
       "math                                   0\n",
       "urdu                                   0\n",
       "grade                                  0\n",
       "school_type                            0\n",
       "studied_at_same_school_as_last_year    0\n",
       "teacher_sex                            0\n",
       "teacher_survey_absent_emergency        0\n",
       "teacher_survey_absent_office_work      0\n",
       "teacher_survey_absent_other_work       0\n",
       "teacher_from_mauza                     0\n",
       "child_studied_at_diff_school           0\n",
       "radio                                  0\n",
       "television                             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2004_num = df2004.copy()\n",
    "df2004_num = df2004_num.drop(columns = ['teacher_years_teaching', 'teachercode', 'teacher_qualifications',\n",
    "                    'teacher_training', 'type_of_housework_timeslot_5', 'child_helped',\n",
    "                    'teacher_rates_child_how_good_in_studies',\n",
    "                    'child_days_absent_last_mo', 'hh_child_in_govt_primary_school',\n",
    "                    'supervisor_code', 'tehsil_census_code',\n",
    "                    'hhid'])\n",
    "print('Numeric-Only DataFrame for 2004:\\n')\n",
    "df2004_num.info()\n",
    "print('\\n\\nNo NaNs or \"None\" objects:\\n')\n",
    "df2004_num.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I cram the data into a normal bell curve using boxcox and then add the fitted data into the grades DataFrame. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxcox and df2003.grade_median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boxcox will not compute numbers less than or equal to 0, so I replace 0s with the next closest number: 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2004.grade_median.replace(to_replace=0, value=1, inplace=True)\n",
    "df2004.grade_median.where(df2004.grade_median < 0.001).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_data_03, fitted_lambda_03 = stats.boxcox(df2003.grade_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxcox and df2004.grade_median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boxcox will not compute numbers less than or equal to 0, so I replace 0s with the next closest number: 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2004.grade_median.replace(to_replace=0, value=1, inplace=True)\n",
    "df2004.grade_median.where(df2004.grade_median < 0.001).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_data_04, fitted_lambda_04 = stats.boxcox(df2004.grade_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the fitted data in the DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add two columns of the fitted data from boxcox\n",
    "df2003.insert(1, 'grade_median_fitted', fitted_data_03)\n",
    "df2003_num.insert(1, 'grade_median_fitted', fitted_data_03)\n",
    "df2004.insert(1, 'grade_median_fitted', fitted_data_04)\n",
    "df2004_num.insert(1, 'grade_median_fitted', fitted_data_04)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare and Contrast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare for Predictive Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Reshape Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create arrays for features and target variable\n",
    "y2003 = df2003_num['grade_median_fitted'].copy().values\n",
    "X2003 = df2003_num.copy().drop(['grade_median', 'grade_median_fitted'], axis=1)\n",
    "X2003_no_derivatives = df2003_num.copy().drop(['grade_median', 'grade_median_fitted',\n",
    "                                'math', 'english', 'urdu'], axis=1)\n",
    "X2003_columns = X2003.copy().columns\n",
    "\n",
    "y2004 = df2004_num['grade_median_fitted'].copy().values\n",
    "X2004 = df2004_num.copy().drop('grade_median_fitted', axis=1)\n",
    "X2004_no_derivatives = df2004_num.copy().drop(['grade_median', 'grade_median_fitted',\n",
    "                                'math', 'english', 'urdu'], axis=1)\n",
    "X2004_columns = X2004.copy().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.indexes.base.Index'>\n"
     ]
    }
   ],
   "source": [
    "print(type(y2003))\n",
    "print(type(X2003))\n",
    "print(type(X2003_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Unscaled Features:\n",
      " childcode                       7.828129e+06\n",
      "child_teachercode               7.828157e+05\n",
      "child_schoolid1                 1.001404e+01\n",
      "english                         4.994642e+02\n",
      "urdu                            4.995004e+02\n",
      "math                            4.995823e+02\n",
      "student_sex                     5.531792e-01\n",
      "grade                           3.018497e+00\n",
      "teacher_sex                     4.438481e-01\n",
      "salary_monthly_Rs               4.147607e+03\n",
      "teacher_from_mauza              3.589595e-01\n",
      "teacher_days_absent_last_mo     2.122543e+00\n",
      "own_agri_land_last_2_seasons    4.661024e+00\n",
      "dtype: float64\n",
      "\n",
      "Standard Deviation of Unscaled Features:\n",
      " childcode                       4.508897e+06\n",
      "child_teachercode               4.508895e+05\n",
      "child_schoolid1                 1.787662e+01\n",
      "english                         1.498868e+02\n",
      "urdu                            1.499514e+02\n",
      "math                            1.496158e+02\n",
      "student_sex                     4.971639e-01\n",
      "grade                           1.347404e-01\n",
      "teacher_sex                     4.968370e-01\n",
      "salary_monthly_Rs               2.274662e+03\n",
      "teacher_from_mauza              4.796953e-01\n",
      "teacher_days_absent_last_mo     3.266275e+00\n",
      "own_agri_land_last_2_seasons    1.194313e+00\n",
      "dtype: float64\n",
      "\n",
      "Mean of Scaled Features:\n",
      " -1.5480922210869235e-17\n",
      "\n",
      "Standard Deviation of Scaled Features:\n",
      " 0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "# Scale the features\n",
    "X_scaled = scale(X2003)\n",
    "\n",
    "# Print the mean and standard deviation of the unscaled features\n",
    "print(\"Mean of Unscaled Features:\\n {}\".format(np.mean(X2003))) \n",
    "print(\"\\nStandard Deviation of Unscaled Features:\\n {}\".format(np.std(X2003)))\n",
    "\n",
    "# Print the mean and standard deviation of the scaled features\n",
    "print(\"\\nMean of Scaled Features:\\n {}\".format(np.mean(X_scaled))) \n",
    "print(\"\\nStandard Deviation of Scaled Features:\\n {}\".format(np.std(X_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2146778415.2901816, tolerance: 1198060.5312518398\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2183586806.1771164, tolerance: 1213620.1200070004\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2194843208.9776044, tolerance: 1223249.6982851464\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2169535311.2477016, tolerance: 1213069.624230217\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2171952964.502136, tolerance: 1204821.0387297203\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned ElasticNet Alpha: {'elasticnet__l1_ratio': 1.0}\n",
      "Tuned ElasticNet R squared: 0.9376980308186561\n"
     ]
    }
   ],
   "source": [
    "# Setup the pipeline steps\n",
    "steps = [\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('elasticnet', ElasticNet())]\n",
    "\n",
    "#Create the pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Specify the hyperparameter space\n",
    "parameters = {'elasticnet__l1_ratio': np.linspace(0, 1, 30)}\n",
    "\n",
    "# Create train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X2003, y2003, test_size=0.4, random_state=42)\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "gm_cv = GridSearchCV(pipeline, parameters)\n",
    "\n",
    "# Fit to the training set\n",
    "gm_cv.fit(X_train, y_train)\n",
    "\n",
    "#Compute and print the metrics\n",
    "r2 = gm_cv.score(X_test, y_test)\n",
    "print('Tuned ElasticNet Alpha: {}'.format(gm_cv.best_params_))\n",
    "print('Tuned ElasticNet R squared: {}'.format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Unscaled Features:\n",
      " grade_median                           4.949026e+02\n",
      "childcode                              8.550843e+06\n",
      "child_teachercode                      8.551006e+05\n",
      "student_sex                            4.457473e-01\n",
      "english                                5.438722e+02\n",
      "math                                   5.359929e+02\n",
      "urdu                                   5.521113e+02\n",
      "grade                                  3.965944e+00\n",
      "school_type                            3.568330e+00\n",
      "studied_at_same_school_as_last_year    3.778286e+00\n",
      "teacher_sex                            4.967517e+00\n",
      "teacher_survey_absent_emergency        4.967034e+00\n",
      "teacher_survey_absent_office_work      4.965337e+00\n",
      "teacher_survey_absent_other_work       4.967517e+00\n",
      "teacher_from_mauza                     4.967673e+00\n",
      "child_studied_at_diff_school           1.701190e+00\n",
      "radio                                  1.979881e+00\n",
      "television                             1.977701e+00\n",
      "dtype: float64\n",
      "\n",
      "Standard Deviation of Unscaled Features:\n",
      " grade_median                           1.557357e+02\n",
      "childcode                              4.619418e+06\n",
      "child_teachercode                      4.620126e+05\n",
      "student_sex                            4.970479e-01\n",
      "english                                1.398075e+02\n",
      "math                                   1.553066e+02\n",
      "urdu                                   1.472320e+02\n",
      "grade                                  2.251205e-01\n",
      "school_type                            2.191453e+00\n",
      "studied_at_same_school_as_last_year    1.862780e+00\n",
      "teacher_sex                            3.871685e-01\n",
      "teacher_survey_absent_emergency        3.926989e-01\n",
      "teacher_survey_absent_office_work      4.115504e-01\n",
      "teacher_survey_absent_other_work       3.871685e-01\n",
      "teacher_from_mauza                     3.853674e-01\n",
      "child_studied_at_diff_school           2.229397e+00\n",
      "radio                                  2.054999e+00\n",
      "television                             2.056567e+00\n",
      "dtype: float64\n",
      "\n",
      "Mean of Scaled Features: 1.4650682539774438e-16\n",
      "\n",
      "Standard Deviation of Scaled Features:\n",
      " 1.0000000000000004\n"
     ]
    }
   ],
   "source": [
    "# Scale the features\n",
    "X_scaled = scale(X2004)\n",
    "\n",
    "# Print the mean and standard deviation of the unscaled features\n",
    "print(\"Mean of Unscaled Features:\\n {}\".format(np.mean(X2004))) \n",
    "print(\"\\nStandard Deviation of Unscaled Features:\\n {}\".format(np.std(X2004)))\n",
    "\n",
    "# Print the mean and standard deviation of the scaled features\n",
    "print(\"\\nMean of Scaled Features: {}\".format(np.mean(X_scaled))) \n",
    "print(\"\\nStandard Deviation of Scaled Features:\\n {}\".format(np.std(X_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11319566536.007917, tolerance: 8494883.720275596\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11224976579.818836, tolerance: 8445229.432611685\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11261959037.666258, tolerance: 8468482.711045302\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11267280021.272419, tolerance: 8473063.575459108\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11262767204.988363, tolerance: 8476135.308926236\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned ElasticNet Alpha: {'elasticnet__l1_ratio': 1.0}\n",
      "Tuned ElasticNet R squared: 0.9860335059826288\n"
     ]
    }
   ],
   "source": [
    "# Setup the pipeline steps\n",
    "steps = [\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('elasticnet', ElasticNet())]\n",
    "\n",
    "#Create the pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Specify the hyperparameter space\n",
    "parameters = {'elasticnet__l1_ratio': np.linspace(0, 1, 30)}\n",
    "\n",
    "# Create train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X2004, y2004, test_size=0.4, random_state=42)\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "gm_cv = GridSearchCV(pipeline, parameters)\n",
    "\n",
    "# Fit to the training set\n",
    "gm_cv.fit(X_train, y_train)\n",
    "\n",
    "#Compute and print the metrics\n",
    "r2 = gm_cv.score(X_test, y_test)\n",
    "print('Tuned ElasticNet Alpha: {}'.format(gm_cv.best_params_))\n",
    "print('Tuned ElasticNet R squared: {}'.format(r2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
