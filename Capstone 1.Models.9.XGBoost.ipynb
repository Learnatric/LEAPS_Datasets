{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import pandas_profiling\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context('poster')\n",
    "from sklearn.impute import SimpleImputer\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from pandas.plotting import scatter_matrix\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from pandas.plotting import parallel_coordinates\n",
    "from pandas.plotting import lag_plot\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "## Load Relevant 2003 and 2004 LEAPS Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2003 leaps data\n",
    "child_03 = pd.read_stata('/Users/bentaylor/Documents/Data/LEAPS data/2003/public_child1.dta',\n",
    "            columns = ['childcode', 'ch1_s1q3'])\n",
    "child_roster_03 = pd.read_stata('/Users/bentaylor/Documents/Data/LEAPS data/2003/public_childroster1.dta',\n",
    "            columns = ['childcode', 'cr1_s1q5', 'cr1_s2q6'])\n",
    "hhs_household_03 = pd.read_stata('/Users/bentaylor/Documents/Data/LEAPS data/2003/public_hhsurvey1_household.dta',\n",
    "            columns = ['hhid', 'mauzaid', 'hf1_s13q1_have', 'hf1_s13q3_have', 'hm1_s11q1'])\n",
    "master_children_03 = pd.read_stata('/Users/bentaylor/Documents/Data/LEAPS data/2003/public_master_children1.dta',\n",
    "            columns = ['childcode', 'hhid', 'child_teachercode1', 'child_schoolid1',\n",
    "                      'child_english_scale1', 'child_urdu_scale1', 'child_math_scale1', 'child_female'])\n",
    "teacher_roster_03 = pd.read_stata('/Users/bentaylor/Documents/Data/LEAPS data/2003/public_teacherroster1.dta',\n",
    "            columns = ['child_teachercode1', 'tr1_s1q2', 'tr1_s1q4', 'tr1_s1q7', 'tr1_s1q8', 'tr1_s1q9',\n",
    "                       'tr1_s1q10', 'tr1_s1q11'])\n",
    "                \n",
    "# 2004 leaps data\n",
    "master_children_04 = pd.read_stata('/Users/bentaylor/Documents/Data/LEAPS data/2004/public_master_children2.dta',\n",
    "            columns = ['childcode', 'hhid', 'child_teachercode2', 'child_female','child_english_scale2', 'child_math_scale2', 'child_urdu_scale2', 'child_class2'])\n",
    "child_04 = pd.read_stata('/Users/bentaylor/Documents/Data/LEAPS data/2004/public_child2.dta',\n",
    "            columns = ['childcode', 'ch2_s1q3', 'ch2_s2q2', 'ch2_s2q3']) # ch2_s0q1_code from correlation assessment\n",
    "child_roster_04 = pd.read_stata('/Users/bentaylor/Documents/Data/LEAPS data/2004/public_childroster2.dta',\n",
    "            columns = ['childcode', 'cr2_s2q6', 'cr2_s2q7'])\n",
    "hhs_household_04 = pd.read_stata('/Users/bentaylor/Documents/Data/LEAPS data/2004/public_hhsurvey2_household.dta', convert_categoricals=False,\n",
    "            columns = ['hhid', 'h2_s0q1_code', 'h2_s13q8', 'h2_s0q4_code'])\n",
    "hhs_member_04 = pd.read_stata('/Users/bentaylor/Documents/Data/LEAPS data/2004/public_hhsurvey2_member.dta',\n",
    "            columns = ['hhid', 'h2_s4q3_type', 'h2_s4q4',\n",
    "                        'h2_s10q4_sub2', 'h2_s5q2e3'])\n",
    "hhs_school_04 = pd.read_stata('/Users/bentaylor/Documents/Data/LEAPS data/2004/public_hhsurvey2_school.dta',\n",
    "            columns = ['hhid'])\n",
    "teacher_04 = pd.read_stata('/Users/bentaylor/Documents/Data/LEAPS data/2004/public_teacher2.dta',\n",
    "            columns = ['teachercode2t','tq2_s3q1','tq2_s8q1','tq2_s8q3', 'tq2_s8q5'])\n",
    "teacher_roster_04 = pd.read_stata('/Users/bentaylor/Documents/Data/LEAPS data/2004/public_teacherroster2.dta',\n",
    "            columns = ['teachercode2tr', 'tr2_q4', 'tr2_q8', 'tr2_q7', 'tr2_q11'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make DataFrame for 2003: df2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_03 = master_children_03.rename(columns = {'child_english_scale1': 'english', 'child_urdu_scale1': \n",
    "                'urdu', 'child_math_scale1': 'math', 'child_female': 'student_sex'})\n",
    "\n",
    "merge1_03 = pd.merge(grades_03, child_roster_03,\n",
    "                on = 'childcode', how = 'left',suffixes=('left','right'))\n",
    "merge1_03 = merge1_03.rename(columns = {'childcode': 'childcode', 'cr1_s1q5': 'grade',\n",
    "                'cr1_s2q6': 'teacher_rates_child_how_good_in_studies'})\n",
    "\n",
    "merge2_03 = pd.merge(merge1_03, child_03,\n",
    "                on = 'childcode', how = 'left', suffixes = ('left','right'))\n",
    "merge2_03 = merge2_03.rename(columns = {'childcode': 'childcode',\n",
    "                'ch1_s1q3': 'child_studied_at_diff_school'})\n",
    "\n",
    "merge3_03 = pd.merge(merge2_03, teacher_roster_03,\n",
    "                on = 'child_teachercode1', how = 'left', suffixes = ('left','right'))\n",
    "merge3_03 = merge3_03.rename(columns = {'child_teachercode1': 'child_teachercode', 'tr1_s1q2': 'teacher_sex',\n",
    "                'tr1_s1q4': 'teacher_years_teaching',\n",
    "                'tr1_s1q7': 'teacher_qualifications', 'tr1_s1q8': 'teacher_training', 'tr1_s1q9': 'salary_monthly_Rs',\n",
    "                'tr1_s1q10': 'teacher_from_mauza',\n",
    "                'tr1_s1q11': 'teacher_days_absent_last_mo'})\n",
    "\n",
    "df2003 = pd.merge(merge3_03, hhs_household_03,\n",
    "                on = 'hhid', how = 'left', suffixes = ('left','right'))\n",
    "df2003 = df2003.rename(columns = {                                \n",
    "                'hhid': 'hhid', 'hf1_s13q1_have': 'print_have',\n",
    "                'hf1_s13q3_have': 'i_vis_have', # df2004.tv corresponds with this.\n",
    "                'hm1_s10q1': 'death_5_years',\n",
    "                'hm1_s11q1': 'own_agri_land_last_2_seasons'})\n",
    "\n",
    "# add grade_median and grade_mean to df2003\n",
    "df2003.insert(0, 'grade_median', df2003.iloc[:,3:6].median(numeric_only = True, axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make DataFrame for 2004: df2004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_04 = master_children_04\n",
    "grades_04 = grades_04.rename(columns = {'childcode': 'childcode', 'hhid': 'hhid',\n",
    "                'child_teachercode2': 'child_teachercode',\n",
    "                'child_female': 'student_sex', 'child_english_scale2': 'english',\n",
    "                'child_math_scale2': 'math', 'child_urdu_scale2': 'urdu', 'child_class2': 'grade'})\n",
    "\n",
    "# 04 hh_surveys\n",
    "merge1_04 = pd.merge(grades_04, hhs_household_04, on = 'hhid', how = 'left')\n",
    "\n",
    "merge2_04 = pd.merge(merge1_04, hhs_member_04, on = 'hhid', how = 'left')\n",
    "merge2_04 = merge2_04.rename(columns = {'h2_s4q3_type': 'school_type',\n",
    "                'h2_s4q4': 'studied_at_same_school_as_last_year'})\n",
    "\n",
    "merge3_04 = pd.merge(merge2_04, hhs_school_04, on='hhid', how='left')\n",
    "\n",
    "# 04 teachers\n",
    "teacher_04 = teacher_04.rename(columns = {'teachercode2t': 'teachercode','tq2_s3q1': 'teacher_sex',\n",
    "                'tq2_s8q1': 'teacher_survey_absent_emergency', 'tq2_s8q3':'teacher_survey_absent_office_work',\n",
    "                'tq2_s8q5': 'teacher_survey_absent_other_work'})\n",
    "merge3_04.insert(2, 'teachercode', teacher_04['teachercode']) # merge3_04 needs column 'teachercode' to merge on.\n",
    "merge4_04 = pd.merge(merge3_04, teacher_04,\n",
    "                on = 'teachercode', how = 'left') # this is a new kind of data, corresponding to teacher_days_absent_last_mo\n",
    "\n",
    "teacher_roster_04 = teacher_roster_04.rename(columns = {'teachercode2tr': 'teachercode',\n",
    "                'tr2_q4': 'teacher_years_teaching',\n",
    "                'tr2_q7': 'teacher_qualifications', 'tr2_q8': 'teacher_training',\n",
    "                'tr2_q11': 'teacher_from_mauza'})\n",
    "merge5_04 = pd.merge(merge4_04, teacher_roster_04, on = 'teachercode', how = 'left')\n",
    "\n",
    "# 04 students\n",
    "merge6_04 = pd.merge(merge5_04, child_04, on = 'childcode', how = 'left')\n",
    "merge6_04 = merge6_04.rename(columns = {'ch2_s1q3': 'child_studied_at_diff_school',\n",
    "                'ch2_s2q2': 'radio', 'ch2_s2q3': 'television'}) # radio and TV replace audio and vis_i of 2003\n",
    "                      \n",
    "merge7_04 = pd.merge(merge6_04, child_roster_04, on = 'childcode', how = 'left')\n",
    "df2004 = merge7_04.rename(columns = {'cr2_s2q6': 'child_days_absent_last_mo',\n",
    "                # The online data does not specify 'month', but must be monthly because the range is 0-31.\n",
    "                'cr2_s2q7': 'teacher_rates_child_how_good_in_studies', 'h2_s0q1_code': 'supervisor_code',\n",
    "                'h2_s13q8': 'hh_child_in_govt_primary_school', 'h2_s0q4_code': 'tehsil_census_code',\n",
    "                'h2_s10q4_sub2': 'child_helped', 'h2_s5q2e3': 'type_of_housework_timeslot_5'})\n",
    "\n",
    "# add grade_median and grade_mean to df2004\n",
    "df2004.insert(0, 'grade_median', df2004.iloc[:, 4:7].median(numeric_only = True, axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of and Solutions for df2003 and df2004\n",
    "### df2003 Analysis\n",
    "The English, Urdu, and Math columns have several NaNs, and the median of the three are the target variable. They must all be dropped.<br>\n",
    "Household (12,738) and teacher (~7,350) questionnaires can be left as NaN, as that's how the data gatherers intended the missing amount to look (unless I want to fill the missing events for those who filled out the questionnaires).<br><br>\n",
    "\n",
    "### df2004 Analysis\n",
    "As with df2003, The English, Urdu, and Math columns have several NaNs, and the median of the three are the target variable. They must all be dropped.<br>\n",
    "The Household (~8,100) and teacher (10,8361) questionnaires can be left as NaN, as that's how the data gatherers intended the missing amount to look (unless I want to fill the missing events for those who filled out the questionnaires).<br><br>\n",
    "\n",
    "### Solutions\n",
    "(The true target variable is the median of english, urdu, and math, and the three grades it is based on I here call the target variables in order to avoid encumbersome language.)<br>\n",
    "I will drop all the rows with NaN instances in the grade_median columns of each DataFrame because they constitute the target variable for predictive modeling.\n",
    "<br><br>\n",
    "I will fill the missing data that is less than 3% with the most common value, except for the \"sex\" column in df2004, which I will fill with the less common value \"Male\" (viz. 1).\n",
    "<br><br>\n",
    "(I have already dropped the missing data for my target variables in the grades DataFrame.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTIONS\n",
    "\n",
    "What do I do with majorly missing data? It's not a problem conceptually but is when I think of how to put it in code.<br>\n",
    "Should I convert grade to integers? (3rd or 4th grade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop all NaN values from the target variable per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2003 = df2003[df2003['grade_median'].notna()]\n",
    "df2003 = df2003[df2003['english'].notna()]\n",
    "df2003 = df2003[df2003['urdu'].notna()]\n",
    "df2003 = df2003[df2003['math'].notna()]\n",
    "\n",
    "df2004 = df2004[df2004['grade_median'].notna()]\n",
    "df2004 = df2004[df2004['english'].notna()]\n",
    "df2004 = df2004[df2004['urdu'].notna()]\n",
    "df2004 = df2004[df2004['math'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df2003: Fill in the missing values of the missing data that is less than 3%. I use sklearn.impute.SimpleImputer¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imr = SimpleImputer(strategy='most_frequent')\n",
    "imr = imr.fit(df2003[['teacher_training']])\n",
    "df2003.teacher_training = imr.transform(df2003[['teacher_training']]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "imr = SimpleImputer(strategy='most_frequent')\n",
    "imr = imr.fit(df2003[['teacher_days_absent_last_mo']])\n",
    "df2003.teacher_days_absent_last_mo = imr.transform(df2003[['teacher_days_absent_last_mo']]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "imr = SimpleImputer(strategy='most_frequent')\n",
    "imr = imr.fit(df2003[['teacher_days_absent_last_mo']])\n",
    "df2003.teacher_days_absent_last_mo = imr.transform(df2003[['teacher_days_absent_last_mo']]).ravel()\n",
    "# I change the floats to integers because no one missed a fraction of a day in this survey,\n",
    "# indicating such was not an option for participants.\n",
    "df2003.teacher_days_absent_last_mo = df2003.teacher_days_absent_last_mo.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "imr = SimpleImputer(strategy='most_frequent')\n",
    "imr = imr.fit(df2003[['teacher_from_mauza']])\n",
    "df2003.teacher_from_mauza = imr.transform(df2003[['teacher_from_mauza']]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "imr = SimpleImputer(strategy='most_frequent')\n",
    "imr = imr.fit(df2003[['teacher_years_teaching']])\n",
    "df2003.teacher_years_teaching = imr.transform(df2003[['teacher_years_teaching']]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "imr = SimpleImputer(strategy='most_frequent')\n",
    "imr = imr.fit(df2003[['salary_monthly_Rs']])\n",
    "df2003.salary_monthly_Rs = imr.transform(df2003[['salary_monthly_Rs']]).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df2004: Fill in the missing values of the missing data that is less than 3%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "imr = SimpleImputer(strategy='most_frequent')\n",
    "imr = imr.fit(df2004[['child_teachercode']])\n",
    "df2004.child_teachercode = imr.transform(df2004[['child_teachercode']]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "imr = SimpleImputer(strategy='most_frequent')\n",
    "imr = imr.fit(df2004[['grade']])\n",
    "df2004.grade = imr.transform(df2004[['grade']]).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If I had more computing power, I would fill the missing ~3% of data using MICE (see code below) instead of the average in each category.<br>\n",
    "cf. https://towardsdatascience.com/stop-using-mean-to-fill-missing-data-678c0d396e22\n",
    "<br><br>\n",
    "\n",
    "from impyute.imputation.cs import mice <br>\n",
    "\n",
    "X = grades.drop('childcode', axis=1).values <br>\n",
    "\n",
    "imputed = mice(X) <br>\n",
    "mice_ages = imputed[:, 2]\n",
    "\n",
    "grades.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back to Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert strings to integers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I performed this after the Cleaning Data section to make more intuitive graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Dictionaries\n",
    "# 5 is the number for NaNs\n",
    "sex_int = {'Female': 0, 'Male': 1, np.nan: 5}\n",
    "yes_no_int = {'No': 0, 'no': 0, 'Yes': 1, 'yes': 1, np.nan: 5}\n",
    "school_type_int = {'Public': 0, 'Private': 1, 'Madrassa': 2, np.nan: 5}\n",
    "\n",
    "# df2003\n",
    "df2003.student_sex = [sex_int[item] for item in df2003.student_sex] \n",
    "df2003.teacher_sex = [sex_int[item] for item in df2003.teacher_sex]\n",
    "df2003.child_studied_at_diff_school = [yes_no_int[item] for item in df2003.child_studied_at_diff_school]\n",
    "df2003.own_agri_land_last_2_seasons = [yes_no_int[item] for item in df2003.own_agri_land_last_2_seasons]\n",
    "df2003.i_vis_have = [yes_no_int[item] for item in df2003.i_vis_have]\n",
    "df2003.print_have = [yes_no_int[item] for item in df2003.print_have]\n",
    "df2003.teacher_from_mauza = [yes_no_int[item] for item in df2003.teacher_from_mauza]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2004.student_sex = [sex_int[item] for item in df2004.student_sex]\n",
    "df2004.teacher_sex = [sex_int[item] for item in df2004.teacher_sex]\n",
    "df2004.school_type = [school_type_int[item] for item in df2004.school_type]\n",
    "df2004.studied_at_same_school_as_last_year = [yes_no_int[item] for item in df2004.studied_at_same_school_as_last_year]\n",
    "df2004.teacher_survey_absent_emergency = [yes_no_int[item] for item in df2004.teacher_survey_absent_emergency]\n",
    "df2004.teacher_survey_absent_office_work = [yes_no_int[item] for item in df2004.teacher_survey_absent_office_work]\n",
    "df2004.teacher_survey_absent_other_work = [yes_no_int[item] for item in df2004.teacher_survey_absent_other_work]\n",
    "df2004.teacher_from_mauza = [yes_no_int[item] for item in df2004.teacher_from_mauza]\n",
    "df2004.child_studied_at_diff_school = [yes_no_int[item] for item in df2004.child_studied_at_diff_school]\n",
    "df2004.radio = [yes_no_int[item] for item in df2004.radio]\n",
    "df2004.television = [yes_no_int[item] for item in df2004.television]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, I fill NaN values with the lesser observed sex: males.\n",
    "imr = SimpleImputer(strategy='constant', fill_value=1)\n",
    "imr = imr.fit(df2004[['student_sex']])\n",
    "df2004.student_sex = imr.transform(df2004[['student_sex']]).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Numeric-Only DataFrames for Predictive Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric-Only DataFrame for 2003:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12110 entries, 0 to 13734\n",
      "Data columns (total 14 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   grade_median                  12110 non-null  float64\n",
      " 1   childcode                     12110 non-null  object \n",
      " 2   child_teachercode             12110 non-null  int32  \n",
      " 3   child_schoolid1               12110 non-null  int8   \n",
      " 4   english                       12110 non-null  float64\n",
      " 5   urdu                          12110 non-null  float64\n",
      " 6   math                          12110 non-null  float64\n",
      " 7   student_sex                   12110 non-null  int64  \n",
      " 8   grade                         12110 non-null  int8   \n",
      " 9   teacher_sex                   12110 non-null  int64  \n",
      " 10  salary_monthly_Rs             12110 non-null  float64\n",
      " 11  teacher_from_mauza            12110 non-null  int64  \n",
      " 12  teacher_days_absent_last_mo   12110 non-null  int64  \n",
      " 13  own_agri_land_last_2_seasons  12110 non-null  int64  \n",
      "dtypes: float64(5), int32(1), int64(5), int8(2), object(1)\n",
      "memory usage: 1.2+ MB\n",
      "\n",
      "\n",
      "No NaNs or \"None\" objects:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "grade_median                    0\n",
       "childcode                       0\n",
       "child_teachercode               0\n",
       "child_schoolid1                 0\n",
       "english                         0\n",
       "urdu                            0\n",
       "math                            0\n",
       "student_sex                     0\n",
       "grade                           0\n",
       "teacher_sex                     0\n",
       "salary_monthly_Rs               0\n",
       "teacher_from_mauza              0\n",
       "teacher_days_absent_last_mo     0\n",
       "own_agri_land_last_2_seasons    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2003_num = df2003.copy()\n",
    "df2003_num = df2003_num.drop(columns = ['hhid',\n",
    "                    'mauzaid', 'teacher_rates_child_how_good_in_studies',\n",
    "                    'teacher_years_teaching', 'teacher_qualifications', 'teacher_training',\n",
    "                    'child_studied_at_diff_school', 'print_have', 'i_vis_have'])\n",
    "print('Numeric-Only DataFrame for 2003:\\n')\n",
    "df2003_num.info()\n",
    "print('\\n\\nNo NaNs or \"None\" objects:\\n')\n",
    "df2003_num.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric-Only DataFrame for 2004:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 64218 entries, 0 to 109147\n",
      "Data columns (total 18 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   grade_median                         64218 non-null  float64\n",
      " 1   childcode                            64218 non-null  int32  \n",
      " 2   child_teachercode                    64218 non-null  float64\n",
      " 3   student_sex                          64218 non-null  float64\n",
      " 4   english                              64218 non-null  float64\n",
      " 5   math                                 64218 non-null  float64\n",
      " 6   urdu                                 64218 non-null  float64\n",
      " 7   grade                                64218 non-null  float64\n",
      " 8   school_type                          64218 non-null  int64  \n",
      " 9   studied_at_same_school_as_last_year  64218 non-null  int64  \n",
      " 10  teacher_sex                          64218 non-null  int64  \n",
      " 11  teacher_survey_absent_emergency      64218 non-null  int64  \n",
      " 12  teacher_survey_absent_office_work    64218 non-null  int64  \n",
      " 13  teacher_survey_absent_other_work     64218 non-null  int64  \n",
      " 14  teacher_from_mauza                   64218 non-null  int64  \n",
      " 15  child_studied_at_diff_school         64218 non-null  int64  \n",
      " 16  radio                                64218 non-null  int64  \n",
      " 17  television                           64218 non-null  int64  \n",
      "dtypes: float64(7), int32(1), int64(10)\n",
      "memory usage: 9.1 MB\n",
      "\n",
      "\n",
      "No NaNs or \"None\" objects:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "grade_median                           0\n",
       "childcode                              0\n",
       "child_teachercode                      0\n",
       "student_sex                            0\n",
       "english                                0\n",
       "math                                   0\n",
       "urdu                                   0\n",
       "grade                                  0\n",
       "school_type                            0\n",
       "studied_at_same_school_as_last_year    0\n",
       "teacher_sex                            0\n",
       "teacher_survey_absent_emergency        0\n",
       "teacher_survey_absent_office_work      0\n",
       "teacher_survey_absent_other_work       0\n",
       "teacher_from_mauza                     0\n",
       "child_studied_at_diff_school           0\n",
       "radio                                  0\n",
       "television                             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2004_num = df2004.copy()\n",
    "df2004_num = df2004_num.drop(columns = ['teacher_years_teaching', 'teachercode', 'teacher_qualifications',\n",
    "                    'teacher_training', 'type_of_housework_timeslot_5', 'child_helped',\n",
    "                    'teacher_rates_child_how_good_in_studies',\n",
    "                    'child_days_absent_last_mo', 'hh_child_in_govt_primary_school',\n",
    "                    'supervisor_code', 'tehsil_census_code',\n",
    "                    'hhid'])\n",
    "print('Numeric-Only DataFrame for 2004:\\n')\n",
    "df2004_num.info()\n",
    "print('\\n\\nNo NaNs or \"None\" objects:\\n')\n",
    "df2004_num.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I cram the data into a normal bell curve using boxcox and then add the fitted data into the grades DataFrame. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxcox and df2003.grade_median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boxcox will not compute numbers less than or equal to 0, so I replace 0s with the next closest number: 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2004.grade_median.replace(to_replace=0, value=1, inplace=True)\n",
    "df2004.grade_median.where(df2004.grade_median < 0.001).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_data_03, fitted_lambda_03 = stats.boxcox(df2003.grade_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxcox and df2004.grade_median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boxcox will not compute numbers less than or equal to 0, so I replace 0s with the next closest number: 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2004.grade_median.replace(to_replace=0, value=1, inplace=True)\n",
    "df2004.grade_median.where(df2004.grade_median < 0.001).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_data_04, fitted_lambda_04 = stats.boxcox(df2004.grade_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the fitted data in the DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add two columns of the fitted data from boxcox\n",
    "df2003.insert(1, 'grade_median_fitted', fitted_data_03)\n",
    "df2003_num.insert(1, 'grade_median_fitted', fitted_data_03)\n",
    "df2004.insert(1, 'grade_median_fitted', fitted_data_04)\n",
    "df2004_num.insert(1, 'grade_median_fitted', fitted_data_04)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare and Contrast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare for Predictive Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Reshape Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create arrays for features and target variable\n",
    "y2003 = df2003_num['grade_median_fitted'].copy().values\n",
    "X2003 = df2003_num.copy().drop(['grade_median', 'grade_median_fitted'], axis=1)\n",
    "X2003_no_derivatives = df2003_num.copy().drop(['grade_median', 'grade_median_fitted',\n",
    "                                'math', 'english', 'urdu'], axis=1)\n",
    "X2003_columns = X2003.copy().columns\n",
    "\n",
    "y2004 = df2004_num['grade_median_fitted'].copy().values\n",
    "X2004 = df2004_num.copy().drop('grade_median_fitted', axis=1)\n",
    "X2004_no_derivatives = df2004_num.copy().drop(['grade_median', 'grade_median_fitted',\n",
    "                                'math', 'english', 'urdu'], axis=1)\n",
    "X2004_columns = X2004.copy().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2003.childcode = X2003.childcode.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X2003, y2003, test_size=.2)\n",
    "\n",
    "train = xgb.DMatrix(X_train, label = y_train)\n",
    "test = xgb.DMatrix(X_test, label = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9688,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9688, 13)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'max_depth': 2, 'eta': 1, 'objective': 'multi:softmax', 'num_class': 3}\n",
    "epochs = 10\n",
    "# param['nthread'] = \n",
    "# param['eval_metric'] = 'auc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "[15:28:22] src/objective/multiclass_obj.cu:110: SoftmaxMultiClassObj: label must be in [0, num_class).\nStack trace:\n  [bt] (0) 1   libxgboost.dylib                    0x0000001a1e926e89 dmlc::LogMessageFatal::~LogMessageFatal() + 57\n  [bt] (1) 2   libxgboost.dylib                    0x0000001a1e9b57b6 xgboost::obj::SoftmaxMultiClassObj::GetGradient(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, int, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float> >*) + 1574\n  [bt] (2) 3   libxgboost.dylib                    0x0000001a1e9232ad xgboost::LearnerImpl::UpdateOneIter(int, xgboost::DMatrix*) + 1149\n  [bt] (3) 4   libxgboost.dylib                    0x0000001a1e941504 XGBoosterUpdateOneIter + 180\n  [bt] (4) 5   libffi.6.dylib                      0x000000010cbe9884 ffi_call_unix64 + 76\n  [bt] (5) 6   ???                                 0x00007ffee3b95fb0 0x0 + 140732718997424\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-59be28ffc67d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \"\"\"\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXGBoostError\u001b[0m: [15:28:22] src/objective/multiclass_obj.cu:110: SoftmaxMultiClassObj: label must be in [0, num_class).\nStack trace:\n  [bt] (0) 1   libxgboost.dylib                    0x0000001a1e926e89 dmlc::LogMessageFatal::~LogMessageFatal() + 57\n  [bt] (1) 2   libxgboost.dylib                    0x0000001a1e9b57b6 xgboost::obj::SoftmaxMultiClassObj::GetGradient(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, int, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float> >*) + 1574\n  [bt] (2) 3   libxgboost.dylib                    0x0000001a1e9232ad xgboost::LearnerImpl::UpdateOneIter(int, xgboost::DMatrix*) + 1149\n  [bt] (3) 4   libxgboost.dylib                    0x0000001a1e941504 XGBoosterUpdateOneIter + 180\n  [bt] (4) 5   libffi.6.dylib                      0x000000010cbe9884 ffi_call_unix64 + 76\n  [bt] (5) 6   ???                                 0x00007ffee3b95fb0 0x0 + 140732718997424\n\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(param, train, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-c0ac8462bce6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X2004, y2004, test_size=.2)\n",
    "\n",
    "train = xgb.DMatrix(X_train, label = y_train)\n",
    "test = xgb.DMatrix(X_test, label = y_test)\n",
    "\n",
    "param = {'max_depth': 2, 'eta': 1, 'objective': 'multi:softmax', 'num_class': 3}\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "[15:29:37] src/objective/multiclass_obj.cu:110: SoftmaxMultiClassObj: label must be in [0, num_class).\nStack trace:\n  [bt] (0) 1   libxgboost.dylib                    0x0000001a1e926e89 dmlc::LogMessageFatal::~LogMessageFatal() + 57\n  [bt] (1) 2   libxgboost.dylib                    0x0000001a1e9b57b6 xgboost::obj::SoftmaxMultiClassObj::GetGradient(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, int, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float> >*) + 1574\n  [bt] (2) 3   libxgboost.dylib                    0x0000001a1e9232ad xgboost::LearnerImpl::UpdateOneIter(int, xgboost::DMatrix*) + 1149\n  [bt] (3) 4   libxgboost.dylib                    0x0000001a1e941504 XGBoosterUpdateOneIter + 180\n  [bt] (4) 5   libffi.6.dylib                      0x000000010cbe9884 ffi_call_unix64 + 76\n  [bt] (5) 6   ???                                 0x00007ffee3b95fb0 0x0 + 140732718997424\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-59be28ffc67d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \"\"\"\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXGBoostError\u001b[0m: [15:29:37] src/objective/multiclass_obj.cu:110: SoftmaxMultiClassObj: label must be in [0, num_class).\nStack trace:\n  [bt] (0) 1   libxgboost.dylib                    0x0000001a1e926e89 dmlc::LogMessageFatal::~LogMessageFatal() + 57\n  [bt] (1) 2   libxgboost.dylib                    0x0000001a1e9b57b6 xgboost::obj::SoftmaxMultiClassObj::GetGradient(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, int, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float> >*) + 1574\n  [bt] (2) 3   libxgboost.dylib                    0x0000001a1e9232ad xgboost::LearnerImpl::UpdateOneIter(int, xgboost::DMatrix*) + 1149\n  [bt] (3) 4   libxgboost.dylib                    0x0000001a1e941504 XGBoosterUpdateOneIter + 180\n  [bt] (4) 5   libffi.6.dylib                      0x000000010cbe9884 ffi_call_unix64 + 76\n  [bt] (5) 6   ???                                 0x00007ffee3b95fb0 0x0 + 140732718997424\n\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(param, train, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-c0ac8462bce6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.predict(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
